* Mean Reciprocal Rank (MRR)
** Motivation
   - We output a list of possibilities and order matters
   - We want to rank models by their ability to rank the best
     result the highest.
   - We want to punish models that don't rank the answer very high.
   - We have many choices for an output
   - Average rank isn't meaningful or interpretable when you have long lists.
** MRR
   - average(1/ranks)
     - where ranks are a vector of ranks of right answer for query.
     - where 1/0 is defined as 0 for reciprocal rank.
     - 0 rank is used if something is missing from the results
   - 1.0 means 1st answer is right
     0.0 means no answer was right
     0.5 means 2nd place was right usually
     0.25 means 4th place was right
     0.1 means 10th
*** Org mode
#+BEGIN_SRC
(org-babel-do-load-languages
 'org-babel-load-languages
 '((python . t)))
(setq org-babel-python-command "python3")
#+END_SRC

** Code

#+BEGIN_SRC python :results output
import numpy

def recip(x):
  if x == 0:
    return 0
  return 1/x

vrecip = numpy.vectorize(recip)

def MRR(ranks):
  return numpy.average(vrecip(ranks))

def apply_MRR(ranks):
  return (ranks, MRR(ranks))

print(apply_MRR([1,1,1,1]))
print(apply_MRR([2,2,2,2]))
print(apply_MRR([3,3,3,3]))
print(apply_MRR([0,1,2,3,4,5]))
print(apply_MRR([0,0,0,0,1]))
print(apply_MRR(numpy.random.random_integers(0,20,size=(20,))))

#+END_SRC

#+RESULTS:
: ([1, 1, 1, 1], 1.0)
: ([2, 2, 2, 2], 0.5)
: ([3, 3, 3, 3], 0.3333333333333333)
: ([0, 1, 2, 3, 4, 5], 0.16666666666666666)
: ([0, 0, 0, 0, 1], 0.2)
: (array([18, 16,  8,  8,  1,  2, 10, 15, 16, 19, 20, 10, 17, 13,  7, 12,  9,
:         0, 14,  2]), 0.16721652831172956)
   
