#+TITLE: Anomaly Detection in Source Code Metrics
#+AUTHOR: Abram Hindle
#+OPTIONS: toc:t
#+PROPERTY: header-args:python :session :results output :exports both

* Introduction
In this notebook, we will explore *anomaly detection* using two popular unsupervised learning
techniques from scikit-learn:

- =IsolationForest= from ~sklearn.ensemble~
- =LocalOutlierFactor= from ~sklearn.neighbors~

We will simulate fake *source code metrics* (e.g., lines of code, cyclomatic complexity,
nesting depth) for a number of files. Then we will inject some *outliers* representing
"weird" or "suspicious" files, and see how both methods flag them.

** What is Isolation Forest

Isolation Forest works by randomly selecting features and splitting
data points to create a binary tree. Anomalies, being few and
different, require fewer splits to isolate compared to normal
instances, resulting in shorter paths in the tree. This structure
helps identify outliers effectively in high-dimensional datasets.

** What is LocalOutlierFactor?

Local Outlier Factor (LOF) identifies anomalies by comparing the local
density of data points. It calculates the density of a point relative
to its neighbors. Points with significantly lower density compared to
their neighbors are deemed outliers, effectively detecting local
anomalies in the data distribution.

** When should we use Isolation Forest and when should we use LocalOutlierFactor?

Use Isolation Forest when dealing with high-dimensional data or when
you expect a large number of anomalies, as it performs well in such
scenarios. Opt for Local Outlier Factor when the data distribution has
varying densities, as it effectively detects anomalies in localized
regions.

** set up org-mode

#+BEGIN_SRC elisp
(org-babel-do-load-languages 'org-babel-load-languages '((python . t)))
(setq org-babel-python-command "python3")
#+END_SRC

#+RESULTS:
: python3

#+BEGIN_SRC python :results output
print("Hello, Org Babel!")
#+END_SRC

#+RESULTS:
: Hello, Org Babel!


** Setup in Python
#+begin_src python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
import pandas as pd
import random
#+end_src

#+RESULTS:
: Python 3.10.12 (main, Aug 15 2025, 14:32:43) [GCC 11.4.0] on linux
: Type "help", "copyright", "credits" or "license" for more information.
: >>> python.el: native completion setup loaded

** Generate Fake Source Code Metrics

We’ll create synthetic feature vectors for files. Each file will have:
- *Lines of Code (LOC)* measures the total number of written lines in a file, indicating size.
- *Cyclomatic Complexity (CC)* assesses code's complexity based on control flow.
- *Maximum Nesting Depth (ND)* identifies the deepest code block nesting, reflecting code clarity.

Normal files will cluster in a reasonable range, while we’ll inject
outliers with extreme values.

#+begin_src python :results output 
rng = np.random.default_rng(42)

n_samples = 200
n_outliers = 10

soft_outliers = True # turn this to true to make outliers closer to the original data

# Normal data
loc = rng.normal(loc=200, scale=50, size=n_samples)       # lines of code
cc = rng.normal(loc=10, scale=3, size=n_samples)          # cyclomatic complexity
nd = rng.normal(loc=4, scale=1, size=n_samples)           # nesting depth

# Outliers: extreme LOC, CC, ND
loc_out = rng.normal(loc=1000, scale=100, size=n_outliers)
cc_out = rng.normal(loc=50, scale=10, size=n_outliers)
nd_out = rng.normal(loc=15, scale=3, size=n_outliers)

if soft_outliers:
    loc_out1 = rng.choice(loc,n_outliers)
    cc_out1 = rng.choice(cc,n_outliers)
    nd_out1 = rng.choice(nd,n_outliers)
    
    def bias_choose(l1,l2):
        l = np.array([l1,l2])
        return l[rng.choice([0,1,1],l1.shape[0]),np.arange(l1.shape[0])]
    
    loc_out = bias_choose(loc_out,loc_out1)
    cc_out = bias_choose(cc_out,cc_out1)
    nd_out = bias_choose(nd_out,nd_out1)


# Combine
X = np.column_stack([np.concatenate([loc, loc_out]),
                     np.concatenate([cc, cc_out]),
                     np.concatenate([nd, nd_out])])

labels = np.array([0]*n_samples + [1]*n_outliers)  # 0 = normal, 1 = injected outlier

df = pd.DataFrame(X, columns=["LOC", "CyclomaticComplexity", "NestingDepth"])
df["Outlier"] = labels
print(df.head(10))
print(df[df["Outlier"] > 0].head(10))
#+end_src

#+RESULTS:
#+begin_example
LOC  CyclomaticComplexity  NestingDepth  Outlier
0  215.235854             11.012724      3.820389        0
1  148.000795             14.222446      4.196776        0
2  237.522560             10.271755      4.820528        0
3  247.028236             11.931816      3.606259        0
4  102.448241              3.849484      4.521167        0
5  134.891025              9.853845      3.734161        0
6  206.392020              7.470309      3.882458        0
7  184.187870              6.343561      4.829519        0
8  199.159942              7.365543      2.006940        0
9  157.347804              8.997630      2.703528        0
             LOC  CyclomaticComplexity  NestingDepth  Outlier
200   153.319116             39.656919     13.678043        1
201   942.246111              9.264166     15.096323        1
202  1127.444722             15.196935      3.943217        1
203   167.260615              3.989433     13.141002        1
204   936.338472             41.934011      6.420415        1
205   248.413918              9.512002     13.399643        1
206   150.523094              6.350320     13.765085        1
207   280.088945             52.416445      3.974137        1
208   222.326559             43.860232      3.692917        1
209   184.532673             10.159466      5.433215        1
#+end_example


* Visualize the Data
Let's see how these features distribute. We'll look at pairwise scatter plots.

Convert this t

#+begin_src python
import seaborn as sns

sns.pairplot(df, hue="Outlier", vars=["LOC", "CyclomaticComplexity", "NestingDepth"])
plt.suptitle("Synthetic Source Code Metrics with Outliers", y=1.02)
plt.show()
#+end_src

#+RESULTS:

* Isolation Forest
=IsolationForest= works by isolating anomalies, since they are easier to separate from
the majority of points.

#+begin_src python
iso = IsolationForest(contamination=n_outliers/(n_samples+n_outliers), random_state=42)
y_pred_iso = iso.fit_predict(X)

# Map sklearn's output (-1 = outlier, 1 = normal) to {0,1}
y_pred_iso = (y_pred_iso == -1).astype(int)

df["IsoForest"] = y_pred_iso

x = pd.crosstab(df["Outlier"], df["IsoForest"], rownames=["True"], colnames=["Predicted"])
print(x)
#+end_src

#+RESULTS:
: Predicted    0  1
: True             
: 0          199  1
: 1            1  9

* Local Outlier Factor
=LocalOutlierFactor= compares the local density of each sample to its neighbors.
Points in sparse regions relative to neighbors are flagged as outliers.

#+begin_src python
lof = LocalOutlierFactor(n_neighbors=20, contamination=n_outliers/(n_samples+n_outliers))
y_pred_lof = lof.fit_predict(X)

# Map sklearn's output (-1 = outlier, 1 = normal) to {0,1}
y_pred_lof = (y_pred_lof == -1).astype(int)

df["LOF"] = y_pred_lof

x = pd.crosstab(df["Outlier"], df["LOF"], rownames=["True"], colnames=["Predicted"])
print(x)
#+end_src

#+RESULTS:
: Predicted    0  1
: True             
: 0          196  4
: 1            4  6

* Compare Methods
Now let’s see how the two approaches perform side by side.

#+begin_src python
print("Isolation Forest detected:", df["IsoForest"].sum(), "outliers")
print("Local Outlier Factor detected:", df["LOF"].sum(), "outliers")

# Visual comparison
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

scatter = axes[0].scatter(X[:,0], X[:,1], c=df["IsoForest"], cmap="coolwarm", edgecolor="k")
axes[0].set_title("Isolation Forest Detection")
axes[0].set_xlabel("LOC")
axes[0].set_ylabel("Cyclomatic Complexity")

scatter = axes[1].scatter(X[:,0], X[:,1], c=df["LOF"], cmap="coolwarm", edgecolor="k")
axes[1].set_title("Local Outlier Factor Detection")
axes[1].set_xlabel("LOC")
axes[1].set_ylabel("Cyclomatic Complexity")

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
: Isolation Forest detected: 10 outliers
: Local Outlier Factor detected: 10 outliers

* Conclusion
Both =IsolationForest= and =LocalOutlierFactor= can detect anomalies, but they differ
in sensitivity and the assumptions they make about data distribution.

- *Isolation Forest*: Great for high-dimensional, large datasets. It builds random partitions.
- *Local Outlier Factor*: Relies on local density estimation, often more sensitive to
  neighborhood structures.

In practice, it’s often good to compare multiple methods when investigating anomalies
in software metrics.
