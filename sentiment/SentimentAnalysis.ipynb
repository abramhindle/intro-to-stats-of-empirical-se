{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "- To determine the emotional affect of text.\n",
    "- Generally done very poorly.\n",
    "- Little agreement on sentiment.\n",
    "- Lots of amazing machine learning performance scores.\n",
    "- Works poorly with software engineering.\n",
    "\n",
    "# LIWC\n",
    "\n",
    "- Word Lists of different categories\n",
    "- https://lit.eecs.umich.edu/geoliwc/liwc_dictionary.html\n",
    "- Not just positive and negative.\n",
    "- Pennebaker, J.W., & Francis, M.E. (1996). Cognitive, emotional, and language processes in disclosure. Cognition and Emotion, 10, 601-626."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Modern\" Sentiment Analysis\n",
    "\n",
    "- Instead of being more descriptive modern senitment analysis has made it easy for computers rather than useful for people.\n",
    "- Typically 2 to 3 labels: Positive, Neutral, Negative, or just Positive and Negative\n",
    "- Ignores context\n",
    "- Simple classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /home/hindle1/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/hindle1/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK Portion based on\n",
    "# Based on https://www.digitalocean.com/community/tutorials/how-to-perform-sentiment-analysis-in-python-3-using-the-natural-language-toolkit-nltk\n",
    "# By By Shaumik Daityari, September 26, 2019\n",
    "#\n",
    "# Run this if you don't have twitter_samples\n",
    "import nltk\n",
    "nltk.download('twitter_samples')\n",
    "# Run this if you don't have vader_lexicon\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Get data\n",
    "\n",
    "- Here's some non-SE data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "text = twitter_samples.strings('tweets.20150430-223406.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)', '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!', '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!', '@97sides CONGRATS :)', 'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark on my fb profile :) in 15 days', '@BhaktisBanter @PallaviRuhail This one is irresistible :)\\n#FlipkartFashionFriday http://t.co/EbZ0L2VENM', \"We don't like to keep our lovely customers waiting for long! We hope you enjoy! Happy Friday! - LWWF :) https://t.co/smyYriipxI\", '@Impatientraider On second thought, there’s just not enough time for a DD :) But new shorts entering system. Sheep must be buying.', 'Jgh , but we have to go to Bayan :D bye', 'As an act of mischievousness, am calling the ETL layer of our in-house warehousing app Katamari.\\n\\nWell… as the name implies :p.']\n",
      "['hopeless for tmr :(', \"Everything in the kids section of IKEA is so cute. Shame I'm nearly 19 in 2 months :(\", '@Hegelbon That heart sliding into the waste basket. :(', '“@ketchBurning: I hate Japanese call him \"bani\" :( :(”\\n\\nMe too', 'Dang starting next week I have \"work\" :(', \"oh god, my babies' faces :( https://t.co/9fcwGvaki0\", '@RileyMcDonough make me smile :((', '@f0ggstar @stuartthull work neighbour on motors. Asked why and he said hates the updates on search :( http://t.co/XvmTUikWln', 'why?:(\"@tahuodyy: sialan:( https://t.co/Hv1i0xcrL2\"', 'Athabasca glacier was there in #1948 :-( #athabasca #glacier #jasper #jaspernationalpark #alberta #explorealberta #… http://t.co/dZZdqmf7Cz']\n"
     ]
    }
   ],
   "source": [
    "print(positive_tweets[0:10])\n",
    "print(negative_tweets[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess -- remove stop words, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.parsing.preprocessing import preprocess_documents\n",
    "positives = preprocess_documents( positive_tweets )\n",
    "negatives = preprocess_documents( negative_tweets )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['followfridai', 'franc', 'int', 'pkuchli', 'milipol', 'pari', 'engag', 'member', 'commun', 'week'], ['lambja', 'hei', 'jame', 'odd', 'contact', 'centr', 'abl', 'assist', 'thank'], ['despiteoffici', 'listen', 'night', 'bleed', 'amaz', 'track', 'scotland'], ['side', 'congrat'], ['yeaaaah', 'yippppi', 'accnt', 'verifi', 'rqst', 'succe', 'got', 'blue', 'tick', 'mark', 'profil', 'dai'], ['bhaktisbant', 'pallaviruhail', 'irresist', 'flipkartfashionfridai', 'http', 'ebzlvenm'], ['like', 'love', 'custom', 'wait', 'long', 'hope', 'enjoi', 'happi', 'fridai', 'lwwf', 'http', 'smyyriipxi'], ['impatientraid', 'second', 'thought', 'there’', 'time', 'new', 'short', 'enter', 'sheep', 'bui'], ['jgh', 'bayan', 'bye'], ['act', 'mischiev', 'call', 'etl', 'layer', 'hous', 'wareh', 'app', 'katamari', 'well…', 'impli']]\n",
      "[['hopeless', 'tmr'], ['kid', 'section', 'ikea', 'cute', 'shame', 'nearli', 'month'], ['hegelbon', 'heart', 'slide', 'wast', 'basket'], ['ketchburn', 'hate', 'japanes', 'bani'], ['dang', 'start', 'week', 'work'], ['god', 'babi', 'face', 'http', 'fcwgvaki'], ['rileymcdonough', 'smile'], ['fggstar', 'stuartthul', 'work', 'neighbour', 'motor', 'ask', 'said', 'hate', 'updat', 'search', 'http', 'xvmtuikwln'], ['tahuodyi', 'sialan', 'http', 'hvixcrl'], ['athabasca', 'glacier', 'athabasca', 'glacier', 'jasper', 'jaspernationalpark', 'alberta', 'explorealberta', 'http', 'dzzdqmfcz']]\n"
     ]
    }
   ],
   "source": [
    "print(positives[0:10])\n",
    "print(negatives[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce vocabulary and move to bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "words = Dictionary(positives + negatives)\n",
    "MAXWORDS=30000\n",
    "words.filter_extremes(no_below=5, no_above=0.5, keep_n=MAXWORDS)\n",
    "positive_docs = [words.doc2bow(doc) for doc in positives]\n",
    "negative_docs = [words.doc2bow(doc) for doc in negatives]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)], [(7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)], [(13, 1), (14, 1), (15, 1), (16, 1)], [(17, 1)], [(18, 1), (19, 1), (20, 1), (21, 1)], [(22, 1), (23, 1), (24, 1), (25, 1)], [(24, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1)], [(35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1)], [(42, 1), (43, 1)], [(44, 1), (45, 1), (46, 1), (47, 1)]]\n",
      "[[], [(152, 1), (180, 1), (619, 1), (630, 1), (1204, 1), (1298, 1)], [(554, 1), (712, 1)], [(545, 1), (703, 1)], [(6, 1), (73, 1), (259, 1)], [(24, 1), (179, 1), (181, 1), (1255, 1)], [(302, 1)], [(24, 1), (73, 1), (475, 1), (545, 1), (751, 1), (830, 1)], [(24, 1)], [(24, 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(positive_docs[0:10])\n",
    "print(negative_docs[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.matutils import sparse2full\n",
    "\n",
    "X = [sparse2full(x,length=MAXWORDS) for x in positive_docs + negative_docs]\n",
    "y = [\"P\" for x in positive_docs] + \\\n",
    "    [\"N\" for x in negative_docs]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X, y, test_size=0.33)\n",
    "\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_hat_train = nb.predict(X_train)\n",
    "y_hat_test  = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2350  978]\n",
      " [ 568 2804]]\n",
      "0.7838971204920325\n",
      "[[1130  542]\n",
      " [ 351 1277]]\n",
      "0.7409341456338845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "print(confusion_matrix(y_train, y_hat_train))\n",
    "print(f1_score(y_train, y_hat_train, pos_label=\"P\"))\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "print(f1_score(y_test, y_hat_test, pos_label=\"P\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here's a rule based learn called Vader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'neg': 0.0, 'neu': 0.615, 'pos': 0.385, 'compound': 0.7579}, {'neg': 0.145, 'neu': 0.585, 'pos': 0.27, 'compound': 0.6229}, {'neg': 0.0, 'neu': 0.706, 'pos': 0.294, 'compound': 0.7959}, {'neg': 0.0, 'neu': 0.123, 'pos': 0.877, 'compound': 0.7983}, {'neg': 0.0, 'neu': 0.718, 'pos': 0.282, 'compound': 0.795}, {'neg': 0.0, 'neu': 0.565, 'pos': 0.435, 'compound': 0.6597}, {'neg': 0.063, 'neu': 0.417, 'pos': 0.52, 'compound': 0.9466}, {'neg': 0.0, 'neu': 0.87, 'pos': 0.13, 'compound': 0.4588}, {'neg': 0.0, 'neu': 0.619, 'pos': 0.381, 'compound': 0.7615}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}]\n",
      "0.8531605113636365\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "scores = [sia.polarity_scores(x) for x in positive_tweets + negative_tweets]\n",
    "print(scores[0:10])\n",
    "pn_scores = [\"N\" if x['neg'] > x['pos'] else \"P\" for x in scores]\n",
    "print(f1_score(y, pn_scores,pos_label=\"P\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Ahmed, T. , Bosu, A., Iqbal, A. and Rahimi, S. 's README for SentiCR\n",
    "\n",
    "https://github.com/senticr/SentiCR\n",
    "\n",
    "Or my python3 version \n",
    "\n",
    "https://github.com/abramhindle/SentiCR\n",
    "\n",
    "\n",
    "# SentiCR\n",
    "\n",
    "SentiCR is an automated sentiment analysis tool for code review comments. SentiCR uses supervised learning algorithms to train\n",
    "models based on 1600 manually label code review comments (https://github.com/senticr/SentiCR/blob/master/SentiCR/oracle.xlsx). Features of SentiCR include:\n",
    "\n",
    "- Special preprocessing steps to exclude URLs and code snippets\n",
    "- Special preprocessing for emoticons\n",
    "- Preprocessing steps for contractions\n",
    "- Special handling of negation phrases through precise identification\n",
    "- Optimized for the SE domain\n",
    "\n",
    "## Performance\n",
    "In our hundred ten-fold cross-validations, SentiCR achieved 83.03% accuracy (i.e., human level accuracy), 67.84% precision,\n",
    "58.35% recall, and 0.62 f-score on a Gradient Boosting Tree based model. Details cross validation results are included here:\n",
    "https://github.com/senticr/SentiCR/tree/master/cross-validation-results\n",
    "\n",
    "## Cite\n",
    "\n",
    "Ahmed, T. , Bosu, A., Iqbal, A. and Rahimi, S., \"SentiCR: A Customized Sentiment Analysis Tool for Code Review Interactions\", In Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering (NIER track).\n",
    "\n",
    "```\n",
    "@INPROCEEDINGS{Ahmed-et-al-SentiCR,\n",
    "   author = {Ahmed, Toufique and Bosu, Amiangshu and Iqbal, Anindya and Rahimi, Shahram},\n",
    "   title = {{SentiCR: A Customized Sentiment Analysis Tool for Code Review Interactions}},\n",
    "   year = {2017},\n",
    "   series = {ASE '17},\n",
    "   booktitle = {32nd IEEE/ACM International Conference on Automated Software Engineering (NIER track)},\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from oracle..\n",
      "Training classifier model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hindle1/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ani', 'continu', 'deleg', 'doe', 'doubl', 'dure', 'els', 'endwhil', 'extend', 'implement', 'includ', 'interfac', 'namespac', 'nativ', 'nowwhil', 'onc', 'ourselv', 'overrid', 'packag', 'privat', 'protect', 'rais', 'readon', 'requir', 'sign', 'synchron', 'themselv', 'tri', 'veri', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure I entirely understand what you are saying. However, looking at file_linux_test.go I'm pretty sure an interface type would be easier for people to use.\n",
      " Score: [-1.]\n",
      "I think it always returns it as 0.\n",
      " Score: [0.]\n",
      "If the steal does not commit, there's no need to clean up _p_'s runq. If it doesn't commit, runqsteal just won't update runqtail, so it won't matter what's in _p_.runq.\n",
      " Score: [-1.]\n",
      "Please change the subject: s:internal/syscall/windows:internal/syscall/windows/registry:\n",
      " Score: [0.]\n",
      "I don't think the name Sockaddr is a good choice here, since it means something very different in the C world.  What do you think of SocketConnAddr instead?\n",
      " Score: [-1.]\n",
      "could we use sed here?  https://go-review.googlesource.com/#/c/10112/1/src/syscall/mkall.sh  it will make the location of the build tag consistent across files (always before the package statement).\n",
      " Score: [0.]\n",
      "Is the implementation hiding here important? This would be simpler still as:  typedef struct GoSeq {   uint8_t *buf;   size_t off;   size_t len;   size_t cap; } GoSeq;\n",
      " Score: [0.]\n",
      "Make sure you test both ways, or a bug that made it always return false would cause the test to pass.  assertTrue(Testpkg.Negate(false));  assertFalse(Testpkg.Negate(true)); + If you want to use the assertEquals form, be sure the message makes clear what actually happened and what was expected (e.g. Negate(true) != false). \n",
      " Score: [0.]\n"
     ]
    }
   ],
   "source": [
    "from SentiCR import  SentiCR\n",
    "\n",
    "sentiment_analyzer=SentiCR()\n",
    "\n",
    "#All examples are acutal code review comments from Go lang\n",
    "\n",
    "sentences=[\"I'm not sure I entirely understand what you are saying. \"+\\\n",
    "           \"However, looking at file_linux_test.go I'm pretty sure an interface type would be easier for people to use.\",\n",
    "           \"I think it always returns it as 0.\",\n",
    "           \"If the steal does not commit, there's no need to clean up _p_'s runq. If it doesn't commit,\"+\\\n",
    "             \" runqsteal just won't update runqtail, so it won't matter what's in _p_.runq.\",\n",
    "           \"Please change the subject: s:internal/syscall/windows:internal/syscall/windows/registry:\",\n",
    "           \"I don't think the name Sockaddr is a good choice here, since it means something very different in \"+\\\n",
    "           \"the C world.  What do you think of SocketConnAddr instead?\",\n",
    "           \"could we use sed here? \"+\\\n",
    "            \" https://go-review.googlesource.com/#/c/10112/1/src/syscall/mkall.sh \"+\\\n",
    "            \" it will make the location of the build tag consistent across files (always before the package statement).\",\n",
    "           \"Is the implementation hiding here important? This would be simpler still as: \"+\\\n",
    "          \" typedef struct GoSeq {   uint8_t *buf;   size_t off;   size_t len;   size_t cap; } GoSeq;\",\n",
    "           \"Make sure you test both ways, or a bug that made it always return false would cause the test to pass. \"+\\\n",
    "        \" assertTrue(Testpkg.Negate(false)); \"+\\\n",
    "        \" assertFalse(Testpkg.Negate(true)); +\"\\\n",
    "        \" If you want to use the assertEquals form, be sure the message makes clear what actually happened and \" +\\\n",
    "        \"what was expected (e.g. Negate(true) != false). \"]\n",
    "\n",
    "for sent in sentences:\n",
    "    score=sentiment_analyzer.get_sentiment_polarity(sent)\n",
    "    print(sent+\"\\n Score: \"+str(score))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.])]\n",
      "0.6852806015875226\n"
     ]
    }
   ],
   "source": [
    "scores = [sentiment_analyzer.get_sentiment_polarity(x) for x in positive_tweets + negative_tweets]\n",
    "print(scores[0:10])\n",
    "pn_scores = [\"N\" if x < 0 else \"P\" for x in scores]\n",
    "print(f1_score(y, pn_scores,pos_label=\"P\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latest deep learning transformer based sentiment analysis\n",
    "\n",
    "- Hugging Face Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Alexander Wong\n",
    "# using transformers to sentiment analysis\n",
    "import nltk\n",
    "from  transformers import pipeline\n",
    "sentence_tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import  word_tokenize\n",
    "tokenizer = TweetTokenizer()\n",
    "N = 600\n",
    "y_hug = [\"P\" for x in range(N)] + [\"N\" for x in range(N)]\n",
    "sentences = [sentence_tokenizer.tokenize(x)[0] for x in positive_tweets[0:N] + negative_tweets[0:N]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through the sentiment analyzer to get pos/neg label and score\n",
    "sentiment_batches = [sentiment_analyzer(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9260645508766174}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_batches[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9260645508766174},\n",
       " {'label': 'POSITIVE', 'score': 0.9929360747337341},\n",
       " {'label': 'POSITIVE', 'score': 0.9997010827064514},\n",
       " {'label': 'POSITIVE', 'score': 0.9924265146255493},\n",
       " {'label': 'NEGATIVE', 'score': 0.9931758046150208},\n",
       " {'label': 'POSITIVE', 'score': 0.9995020627975464},\n",
       " {'label': 'NEGATIVE', 'score': 0.9852420091629028},\n",
       " {'label': 'NEGATIVE', 'score': 0.9981480836868286},\n",
       " {'label': 'POSITIVE', 'score': 0.9309679865837097},\n",
       " {'label': 'POSITIVE', 'score': 0.9934095144271851}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments = [sentence for batch in sentiment_batches for sentence in batch]\n",
    "sentiments[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6245353159851301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "y_hat = [\"N\" if x['label'] == 'NEGATIVE' else 'P' for x in sentiments]\n",
    "print(f1_score(y_hug, y_hat,pos_label=\"P\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
