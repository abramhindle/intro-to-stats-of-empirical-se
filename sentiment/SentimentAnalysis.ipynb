{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /home/hindle1/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/hindle1/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK Portion based on\n",
    "# Based on https://www.digitalocean.com/community/tutorials/how-to-perform-sentiment-analysis-in-python-3-using-the-natural-language-toolkit-nltk\n",
    "# By By Shaumik Daityari, September 26, 2019\n",
    "#\n",
    "# Run this if you don't have twitter_samples\n",
    "import nltk\n",
    "nltk.download('twitter_samples')\n",
    "# Run this if you don't have vader_lexicon\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "text = twitter_samples.strings('tweets.20150430-223406.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)', '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!', '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!', '@97sides CONGRATS :)', 'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark on my fb profile :) in 15 days', '@BhaktisBanter @PallaviRuhail This one is irresistible :)\\n#FlipkartFashionFriday http://t.co/EbZ0L2VENM', \"We don't like to keep our lovely customers waiting for long! We hope you enjoy! Happy Friday! - LWWF :) https://t.co/smyYriipxI\", '@Impatientraider On second thought, there’s just not enough time for a DD :) But new shorts entering system. Sheep must be buying.', 'Jgh , but we have to go to Bayan :D bye', 'As an act of mischievousness, am calling the ETL layer of our in-house warehousing app Katamari.\\n\\nWell… as the name implies :p.']\n",
      "['hopeless for tmr :(', \"Everything in the kids section of IKEA is so cute. Shame I'm nearly 19 in 2 months :(\", '@Hegelbon That heart sliding into the waste basket. :(', '“@ketchBurning: I hate Japanese call him \"bani\" :( :(”\\n\\nMe too', 'Dang starting next week I have \"work\" :(', \"oh god, my babies' faces :( https://t.co/9fcwGvaki0\", '@RileyMcDonough make me smile :((', '@f0ggstar @stuartthull work neighbour on motors. Asked why and he said hates the updates on search :( http://t.co/XvmTUikWln', 'why?:(\"@tahuodyy: sialan:( https://t.co/Hv1i0xcrL2\"', 'Athabasca glacier was there in #1948 :-( #athabasca #glacier #jasper #jaspernationalpark #alberta #explorealberta #… http://t.co/dZZdqmf7Cz']\n"
     ]
    }
   ],
   "source": [
    "print(positive_tweets[0:10])\n",
    "print(negative_tweets[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.parsing.preprocessing import preprocess_documents\n",
    "positives = preprocess_documents( positive_tweets )\n",
    "negatives = preprocess_documents( negative_tweets )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['followfridai', 'franc', 'int', 'pkuchli', 'milipol', 'pari', 'engag', 'member', 'commun', 'week'], ['lambja', 'hei', 'jame', 'odd', 'contact', 'centr', 'abl', 'assist', 'thank'], ['despiteoffici', 'listen', 'night', 'bleed', 'amaz', 'track', 'scotland'], ['side', 'congrat'], ['yeaaaah', 'yippppi', 'accnt', 'verifi', 'rqst', 'succe', 'got', 'blue', 'tick', 'mark', 'profil', 'dai'], ['bhaktisbant', 'pallaviruhail', 'irresist', 'flipkartfashionfridai', 'http', 'ebzlvenm'], ['like', 'love', 'custom', 'wait', 'long', 'hope', 'enjoi', 'happi', 'fridai', 'lwwf', 'http', 'smyyriipxi'], ['impatientraid', 'second', 'thought', 'there’', 'time', 'new', 'short', 'enter', 'sheep', 'bui'], ['jgh', 'bayan', 'bye'], ['act', 'mischiev', 'call', 'etl', 'layer', 'hous', 'wareh', 'app', 'katamari', 'well…', 'impli']]\n",
      "[['hopeless', 'tmr'], ['kid', 'section', 'ikea', 'cute', 'shame', 'nearli', 'month'], ['hegelbon', 'heart', 'slide', 'wast', 'basket'], ['ketchburn', 'hate', 'japanes', 'bani'], ['dang', 'start', 'week', 'work'], ['god', 'babi', 'face', 'http', 'fcwgvaki'], ['rileymcdonough', 'smile'], ['fggstar', 'stuartthul', 'work', 'neighbour', 'motor', 'ask', 'said', 'hate', 'updat', 'search', 'http', 'xvmtuikwln'], ['tahuodyi', 'sialan', 'http', 'hvixcrl'], ['athabasca', 'glacier', 'athabasca', 'glacier', 'jasper', 'jaspernationalpark', 'alberta', 'explorealberta', 'http', 'dzzdqmfcz']]\n"
     ]
    }
   ],
   "source": [
    "print(positives[0:10])\n",
    "print(negatives[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "words = Dictionary(positives + negatives)\n",
    "MAXWORDS=30000\n",
    "words.filter_extremes(no_below=5, no_above=0.5, keep_n=MAXWORDS)\n",
    "positive_docs = [words.doc2bow(doc) for doc in positives]\n",
    "negative_docs = [words.doc2bow(doc) for doc in negatives]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)], [(7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)], [(13, 1), (14, 1), (15, 1), (16, 1)], [(17, 1)], [(18, 1), (19, 1), (20, 1), (21, 1)], [(22, 1), (23, 1), (24, 1), (25, 1)], [(24, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1)], [(35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1)], [(42, 1), (43, 1)], [(44, 1), (45, 1), (46, 1), (47, 1)]]\n",
      "[[], [(152, 1), (180, 1), (619, 1), (630, 1), (1204, 1), (1298, 1)], [(554, 1), (712, 1)], [(545, 1), (703, 1)], [(6, 1), (73, 1), (259, 1)], [(24, 1), (179, 1), (181, 1), (1255, 1)], [(302, 1)], [(24, 1), (73, 1), (475, 1), (545, 1), (751, 1), (830, 1)], [(24, 1)], [(24, 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(positive_docs[0:10])\n",
    "print(negative_docs[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.matutils import sparse2full\n",
    "\n",
    "X = [sparse2full(x,length=MAXWORDS) for x in positive_docs + negative_docs]\n",
    "y = [\"P\" for x in positive_docs] + \\\n",
    "    [\"N\" for x in negative_docs]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X, y, test_size=0.33)\n",
    "\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_hat_train = nb.predict(X_train)\n",
    "y_hat_test  = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2678  685]\n",
      " [ 685 2652]]\n",
      "0.7947258016182199\n",
      "[[1232  405]\n",
      " [ 468 1195]]\n",
      "0.7324547961998161\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "print(confusion_matrix(y_train, y_hat_train))\n",
    "print(f1_score(y_train, y_hat_train, pos_label=\"P\"))\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "print(f1_score(y_test, y_hat_test, pos_label=\"P\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'neg': 0.0, 'neu': 0.615, 'pos': 0.385, 'compound': 0.7579}, {'neg': 0.145, 'neu': 0.585, 'pos': 0.27, 'compound': 0.6229}, {'neg': 0.0, 'neu': 0.706, 'pos': 0.294, 'compound': 0.7959}, {'neg': 0.0, 'neu': 0.123, 'pos': 0.877, 'compound': 0.7983}, {'neg': 0.0, 'neu': 0.718, 'pos': 0.282, 'compound': 0.795}, {'neg': 0.0, 'neu': 0.565, 'pos': 0.435, 'compound': 0.6597}, {'neg': 0.063, 'neu': 0.417, 'pos': 0.52, 'compound': 0.9466}, {'neg': 0.0, 'neu': 0.87, 'pos': 0.13, 'compound': 0.4588}, {'neg': 0.0, 'neu': 0.619, 'pos': 0.381, 'compound': 0.7615}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}]\n",
      "0.8531605113636365\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "scores = [sia.polarity_scores(x) for x in positive_tweets + negative_tweets]\n",
    "print(scores[0:10])\n",
    "pn_scores = [\"N\" if x['neg'] > x['pos'] else \"P\" for x in scores]\n",
    "print(f1_score(y, pn_scores,pos_label=\"P\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from oracle..\n",
      "Training classifier model..\n"
     ]
    }
   ],
   "source": [
    "from SentiCR import  SentiCR\n",
    "\n",
    "sentiment_analyzer=SentiCR()\n",
    "\n",
    "#All examples are acutal code review comments from Go lang\n",
    "\n",
    "sentences=[\"I'm not sure I entirely understand what you are saying. \"+\\\n",
    "           \"However, looking at file_linux_test.go I'm pretty sure an interface type would be easier for people to use.\",\n",
    "           \"I think it always returns it as 0.\",\n",
    "           \"If the steal does not commit, there's no need to clean up _p_'s runq. If it doesn't commit,\"+\\\n",
    "             \" runqsteal just won't update runqtail, so it won't matter what's in _p_.runq.\",\n",
    "           \"Please change the subject: s:internal/syscall/windows:internal/syscall/windows/registry:\",\n",
    "           \"I don't think the name Sockaddr is a good choice here, since it means something very different in \"+\\\n",
    "           \"the C world.  What do you think of SocketConnAddr instead?\",\n",
    "           \"could we use sed here? \"+\\\n",
    "            \" https://go-review.googlesource.com/#/c/10112/1/src/syscall/mkall.sh \"+\\\n",
    "            \" it will make the location of the build tag consistent across files (always before the package statement).\",\n",
    "           \"Is the implementation hiding here important? This would be simpler still as: \"+\\\n",
    "          \" typedef struct GoSeq {   uint8_t *buf;   size_t off;   size_t len;   size_t cap; } GoSeq;\",\n",
    "           \"Make sure you test both ways, or a bug that made it always return false would cause the test to pass. \"+\\\n",
    "        \" assertTrue(Testpkg.Negate(false)); \"+\\\n",
    "        \" assertFalse(Testpkg.Negate(true)); +\"\\\n",
    "        \" If you want to use the assertEquals form, be sure the message makes clear what actually happened and \" +\\\n",
    "        \"what was expected (e.g. Negate(true) != false). \"]\n",
    "\n",
    "for sent in sentences:\n",
    "    score=sentiment_analyzer.get_sentiment_polarity(sent)\n",
    "    print(sent+\"\\n Score: \"+str(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4d2a5e29c285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentiment_analyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSentiCR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#All examples are acutal code review comments from Go lang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m sentences=[\"I'm not sure I entirely understand what you are saying. \"+\\\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "sentiment_analyzer=SentiCR()\n",
    "\n",
    "#All examples are acutal code review comments from Go lang\n",
    "\n",
    "sentences=[\"I'm not sure I entirely understand what you are saying. \"+\\\n",
    "           \"However, looking at file_linux_test.go I'm pretty sure an interface type would be easier for people to use.\",\n",
    "           \"I think it always returns it as 0.\",\n",
    "           \"If the steal does not commit, there's no need to clean up _p_'s runq. If it doesn't commit,\"+\\\n",
    "             \" runqsteal just won't update runqtail, so it won't matter what's in _p_.runq.\",\n",
    "           \"Please change the subject: s:internal/syscall/windows:internal/syscall/windows/registry:\",\n",
    "           \"I don't think the name Sockaddr is a good choice here, since it means something very different in \"+\\\n",
    "           \"the C world.  What do you think of SocketConnAddr instead?\",\n",
    "           \"could we use sed here? \"+\\\n",
    "            \" https://go-review.googlesource.com/#/c/10112/1/src/syscall/mkall.sh \"+\\\n",
    "            \" it will make the location of the build tag consistent across files (always before the package statement).\",\n",
    "           \"Is the implementation hiding here important? This would be simpler still as: \"+\\\n",
    "          \" typedef struct GoSeq {   uint8_t *buf;   size_t off;   size_t len;   size_t cap; } GoSeq;\",\n",
    "           \"Make sure you test both ways, or a bug that made it always return false would cause the test to pass. \"+\\\n",
    "        \" assertTrue(Testpkg.Negate(false)); \"+\\\n",
    "        \" assertFalse(Testpkg.Negate(true)); +\"\\\n",
    "        \" If you want to use the assertEquals form, be sure the message makes clear what actually happened and \" +\\\n",
    "        \"what was expected (e.g. Negate(true) != false). \"]\n",
    "\n",
    "for sent in sentences:\n",
    "    score=sentiment_analyzer.get_sentiment_polarity(sent)\n",
    "    print(sent+\"\\n Score: \"+str(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
